# Guidelines for ETL Project

This document contains guidelines, requirements, and suggestions for Project 1.


## Data Cleanup & Analysis

Once you have identified your datasets, perform ETL on the data. Make sure to plan and document the following:

* The sources of data that you will extract from.

* The type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc).

* The type of final production database to load the data into (relational or non-relational).

* The final tables or collections that will be used in the production database.

You will be required to submit a final technical report with the above information and steps required to reproduce your ETL process.


# FIFA World Cup ETL

# Project Overview:
Based on athlete data from the Olympic games between 1896-2014, we created a  machine learning model to predict who would win a medal in the RIO 2016 Olympic Games. 

We are using Amazon Web Services S3 to host our Olympic athlete's dataset from Kaggle.


# Project Contributors:

* Dharti Patel
* Tanisha Blakely
* Abe Jones
* Alap Raval

# Tech Stack
* Scikit-Learn library for creating ML model for our prediction.
* Amazon AWS S3 to host our Olympic athlete's dataset from Kaggle.
* Python Pandas and Matplotlib libraries for data manipulation and ploting.
* HTML/CSS/Bootstrap for creating web page with our visualizations.
* SandDance for visualizing athlete data correlations.


# Data Source:
https://www.kaggle.com/abecklas/fifa-world-cup/version/5#WorldCups.csv